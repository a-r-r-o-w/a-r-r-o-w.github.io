<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion</title>
    <script>
      (function() {
        const t = localStorage.getItem('theme') || (matchMedia('(prefers-color-scheme: light)').matches ? 'light' : 'dark');
        document.documentElement.dataset.theme = t;
      })();
    </script>
    <link rel="stylesheet" href="/assets/style.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" 
      integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg==" 
      crossorigin="anonymous" referrerpolicy="no-referrer" />
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}, {left: '\\(', right: '\\)', display: false}, {left: '\\[', right: '\\]', display: true}], throwOnError: false});"></script>
    <!-- Copy style from here: https://github.com/highlightjs/highlight.js/tree/5697ae5187746c24732e62cd625f3f83004a44ce/src/styles -->
    <link rel="stylesheet" id="hljs-dark" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark-dimmed.min.css">
    <link rel="stylesheet" id="hljs-light" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css" disabled>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>document.addEventListener('DOMContentLoaded', () => hljs.highlightAll());</script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-R1R7JKELB2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-R1R7JKELB2', {
        'page_title': 'Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion',
        'page_path': '/blog/1_sprout/00001_self_forcing/',
        'allow_google_signals': false,
        'allow_ad_personalization_signals': false
      });
    </script>
</head>
<body data-theme="dark">
    <!-- <header class="sticky"> -->
    <header>
        <div class="header-inner">
            <a href="/"><h1>Aryan V S</h1></a>
            <div class="burger-menu">
                <span></span>
                <span></span>
                <span></span>
            </div>
            <nav>
                <a href="/">Home</a>
                <span class="nav-separator">|</span>
                <a href="/blog/">Blog</a>
            </nav>
            <div class="theme-toggle">
                <label class="switch">
                    <input type="checkbox">
                    <span class="slider"></span>
                </label>
            </div>
        </div>
    </header>
    <div class="container">
        <main>
          <div class="post-title-wrapper">
              <div class="post-date">2025-09-02</div>
              <h2><div class="post-title">Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion</div></h2>
          </div>
            <div class="post-meta">
                <div class="post-tags"><span class="tag">computer-vision</span> <span class="tag">diffusion</span> <span class="tag">autoregression</span> <span class="tag">world-models</span></div>
                <div class="post-authors"><a href=https://www.xunhuang.me/>Xun Huang</a> • <a href=https://zhengqili.github.io/>Zhengqi Li</a> • <a href=https://guandehe.github.io/>Guande He</a> • <a href=https://mingyuanzhou.github.io/>Mingyuan Zhou</a> • <a href=https://research.adobe.com/person/eli-shechtman/>Eli Shechtman</a></div>
                <div class="post-links"><a href="https://github.com/guandeh17/Self-Forcing" class="post-link code"><i class="fab fa-github"></i> Code</a> <a href="https://arxiv.org/abs/2506.08009" class="post-link paper"><i class="fas fa-file-pdf"></i> Paper</a></div>
            </div>
            <ul>
<li>introduces novel paradigm for autogressive diffusion models</li>
<li>addresses exposure bias (models trained on ground truth context must generate sequences conditioned on their own imperfect predictions at inference time)</li>
<li>design of Diffusion Transformers (DiTs) till date denoise all frames simultaneously using bidirectional attention (future frames can affect past frames, and entire video must be generated at once) - authors argue that this is fundamentally limiting their applicability for real-time applications</li>
<li>autoregressive models may help, but usually struggle to match sota video model performance</li>
<li>teacher forcing recap: predict next token conditioned on ground-truth tokens. in context of video diffusion, TF trains model to predict each frame conditioned on previous context frames</li>
<li>self forcing: instead of conditioning on ground-truth frames, model conditions on its own previous predictions, allowing it to learn to generate more realistic frames over time
$$p(\hat{x}^1)p(\hat{x}^2|x^1)p(\hat{x}^3|x^1,x^2)...p(\hat{x}^T|x^{\lt T}) = p(\hat{x}^1, \hat{x}^2, ..., \hat{x}^{T-1})$$</li>
<li>diffusion forcing: trains model on videos with noise levels independently sampled for each frame (denoising each frame based on past noisy context frames) - ensures autoregressive inference scenario where context frames are clean and current frame is noisy
$$p(\hat{x}^1)p(\hat{x}^2|x_{t^1}^1)p(\hat{x}^3|x_{t^1}^1, x_{t^2}^2)...p(\hat{x}^T|x_{t^{\lt T}}^{\lt T}) \neq p(\hat{x}^1, \hat{x}^2, ..., \hat{x}^{T-1})$$</li>
<li>introduces "self forcing": addresses exposure bias. inspired by RNN-era sequence modeling techniques to bridge train-test distribution gap by explicitly unrolling autoregressive generation during training.
<ul>
<li>each frame is conditioned on previously self-generated frames rather than ground truth frames</li>
<li>supervision with distribution-matching losses
$$p(\hat{x}^1)p(\hat{x}^2|\hat{x}^1)p(\hat{x}^3|\hat{x}^1,\hat{x}^2)...p(\hat{x}^T|\hat{x}^{\lt T}) = p(\hat{x}^1, \hat{x}^2, ..., \hat{x}^{T-1})$$</li>
</ul>
</li>
</ul>
<p>todo reading and re-reading:</p>
<ul>
<li><a href="https://arxiv.org/abs/2405.14867" target="_blank" rel="noopener noreferrer">Improved Distribution Matching Distillation for Fast Image Synthesis</a></li>
<li><a href="https://arxiv.org/abs/2311.18828" target="_blank" rel="noopener noreferrer">One-step Diffusion with Distribution Matching Distillation</a></li>
<li><a href="https://arxiv.org/abs/2404.04057" target="_blank" rel="noopener noreferrer">Score Identity Distillation</a></li>
<li><a href="https://arxiv.org/abs/1406.2661" target="_blank" rel="noopener noreferrer">Generative Adversarial Networks</a></li>
</ul>
<p>reading list for exposure bias - some approaches attempt to mitigate distributional mismatch by incorporating noisy context frames during inference:</p>
<ul>
<li><a href="https://arxiv.org/abs/2407.01392" target="_blank" rel="noopener noreferrer">Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion</a></li>
<li><a href="https://oasis-model.github.io/" target="_blank" rel="noopener noreferrer">Oasis: A Universe in a Transformer</a></li>
<li><a href="https://arxiv.org/abs/2504.12626" target="_blank" rel="noopener noreferrer">Packing Input Frame Context in Next-Frame Prediction Models for Video Generation</a></li>
</ul>
<p>reading list for distribution-matching losses:</p>
<ul>
<li><a href="https://arxiv.org/abs/2503.19325" target="_blank" rel="noopener noreferrer">Long-Context Autoregressive Video Modeling with Next-Frame Prediction</a></li>
<li><a href="https://arxiv.org/abs/2405.14867" target="_blank" rel="noopener noreferrer">Improved Distribution Matching Distillation for Fast Image Synthesis</a></li>
<li><a href="https://arxiv.org/abs/2412.07772" target="_blank" rel="noopener noreferrer">From Slow Bidirectional to Fast Autoregressive Video Diffusion Models</a></li>
</ul>

        </main>
    </div>
    <div class="lightbox-overlay" id="lightbox">
      <div class="lightbox-close" onclick="closeLightbox()">×</div>
      <div class="lightbox-content">
          <img class="lightbox-media" id="lightbox-media" src="" alt="">
      </div>
      <div class="lightbox-controls">
          <button class="lightbox-btn" onclick="zoomOut()" title="Zoom Out (-)">−</button>
          <div class="zoom-level" id="zoom-level">100%</div>
          <button class="lightbox-btn" onclick="zoomIn()" title="Zoom In (+)">+</button>
          <button class="lightbox-btn" onclick="resetZoom()" title="Reset (0)">⟲</button>
      </div>
  </div>
    <footer>
        <div class="social-links">
            <a href="https://github.com/a-r-r-o-w" target="_blank" rel="noopener noreferrer" aria-label="GitHub">
                <i class="fab fa-github"></i>
            </a>
            <a href="https://x.com/aryanvs_" target="_blank" rel="noopener noreferrer" aria-label="X (Twitter)">
                <i class="fab fa-x-twitter"></i>
            </a>
            <a href="https://linkedin.com/in/aryan-v-s" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn">
                <i class="fab fa-linkedin"></i>
            </a>
            <a href="mailto:contact.aryanvs@gmail.com" aria-label="Email">
                <i class="fas fa-envelope"></i>
            </a>
        </div>
    </footer>
    <script src="/assets/script.js"></script>
</body>
</html>
