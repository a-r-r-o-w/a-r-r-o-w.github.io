<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>PuLID: Pure and Lightning ID Customization via Contrastive Alignment</title>
    <script>
      (function() {
        const t = localStorage.getItem('theme') || (matchMedia('(prefers-color-scheme: light)').matches ? 'light' : 'dark');
        document.documentElement.dataset.theme = t;
      })();
    </script>
    <link rel="stylesheet" href="/assets/style.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" 
      integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg==" 
      crossorigin="anonymous" referrerpolicy="no-referrer" />
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}, {left: '\\(', right: '\\)', display: false}, {left: '\\[', right: '\\]', display: true}], throwOnError: false});"></script>
    <!-- Copy style from here: https://github.com/highlightjs/highlight.js/tree/5697ae5187746c24732e62cd625f3f83004a44ce/src/styles -->
    <link rel="stylesheet" id="hljs-dark" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github-dark-dimmed.min.css">
    <link rel="stylesheet" id="hljs-light" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/github.min.css" disabled>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
    <script>document.addEventListener('DOMContentLoaded', () => hljs.highlightAll());</script>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-R1R7JKELB2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-R1R7JKELB2', {
        'page_title': 'PuLID: Pure and Lightning ID Customization via Contrastive Alignment',
        'page_path': '/blog/1_sprout/00000_pulid/',
        'allow_google_signals': false,
        'allow_ad_personalization_signals': false
      });
    </script>
</head>
<body data-theme="dark">
    <!-- <header class="sticky"> -->
    <header>
        <div class="header-inner">
            <a href="/"><h1>Aryan V S</h1></a>
            <nav>
                <a href="/">Home</a> | <a href="/blog/">Blog</a>
            </nav>
            <div class="theme-toggle">
                <label class="switch">
                    <input type="checkbox">
                    <span class="slider"></span>
                </label>
            </div>
        </div>
    </header>
    <div class="container">
        <main>
          <div class="post-title-wrapper">
              <div class="post-date">2025-08-02</div>
              <h2><div class="post-title">PuLID: Pure and Lightning ID Customization via Contrastive Alignment</div></h2>
          </div>
            <div class="post-meta">
                <div class="post-tags"><span class="tag">deep-learning</span> <span class="tag">computer-vision</span> <span class="tag">diffusion</span></div>
                <div class="post-authors">Zinan Guo • <a href=https://tothebeginning.github.io/>Yanze Wu</a> • Zhuowei Chen • Lang Chen • Peng Zhang • Qian He</div>
                <div class="post-links"><a href="https://github.com/ToTheBeginning/PuLID" class="post-link code"><i class="fab fa-github"></i> Code</a> <a href="https://arxiv.org/abs/2404.16022" class="post-link paper"><i class="fas fa-file-pdf"></i> Paper</a> <a href="https://openreview.net/forum?id=E6ZodZu" class="post-link openreview"><i class="fas fa-external-link-alt"></i> OpenReview</a></div>
            </div>
            <ul>
<li>proposes a novel tuning-free method for ID customization for T2I diffusion models</li>
<li>image elements (e.g. background, lighting, composition, and style) are kept as consistent as possible</li>
<li>two approaches to achieving ID customization:
<ul>
<li>finetuning based: requires 10s of minutes and economically expensive</li>
<li>pretrained adapter: requires expansive portrait dataset to train encoder</li>
</ul>
</li>
<li>training:
<ul>
<li>introduce "Lightning T2I branch" alongside normal denoising branch</li>
<li>minimizes the influence on original model's behaviour by constructing contrastive pair with same prompt and initial latent, with and without ID insertion</li>
<li>features between contrastive pair aligned semantically, instructing ID adapter how to insert ID info without affecting behaviour or original model</li>
<li>high quality $x_0$ after ID insertion used to extract face embedding and calculate accurate ID loss with the ground truth face embedding</li>
</ul>
</li>
</ul>
<p>Quantitative metrics (from OpenReview <a href="https://openreview.net/forum?id=E6ZodZu0HQ&amp;noteId=wNWF19Gi9B" target="_blank" rel="noopener noreferrer">comment</a>):</p>
<div class="code-block-wrapper"><button class="copy-code-btn" onclick="copyCode(this)">Copy</button><pre><code>Speed↑	FGIS↑	FID↓	Face Div.↑
PhotoMaker	8.69iter/s	0.596	147.62	0.531
IPAdapter	6.08iter/s	0.571	139.33	0.536
InstantID	4.66iter/s	0.592	152.28	0.502
PuLID	5.85iter/s	0.619	89.80	0.527
</code></pre></div>
<p>Method:</p>
<ul>
<li>ID customization for T2I diffusion adds $C_id$ as an additional condition working together with the prompt to control image generation. Typically for tuning free customization, ID features are extracted by employing an encoder (typically a frozen backbone like CLIP image encoder or face recognition backbone along with learnable head). To embed the ID features into pre-trained T2I model, parallel cross-attention layers are used in addition to original ones (say, for text conditioning).</li>
<li>employs a MLP to map features from last layer of CLIP image encoder and <a href="https://arxiv.org/abs/1801.07698" target="_blank" rel="noopener noreferrer">face recognition model</a> to 5 tokens ("global ID features"). Following <a href="https://arxiv.org/abs/2302.13848" target="_blank" rel="noopener noreferrer">ELITE's</a> approach, multi-layer features of CLIP mapped to another 5 tokens ("local ID features").</li>
</ul>
<img src="./pulid_framework.png" alt="Overview of PuLID framework" />
<p>Extra reading:</p>
<ul>
<li>line of work based on finetuning:
<ul>
<li>Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit H Bermano, Gal Chechik, and Daniel Cohen-Or. An image is worth one word: Personalizing text-to-image generation using textual inversion. In ICLR, 2023.</li>
<li>Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir Aberman. Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation. In CVPR, 2023.</li>
<li>Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. In ICLR, 2022.</li>
<li>Nupur Kumari, Bingliang Zhang, Richard Zhang, Eli Shechtman, and Jun-Yan Zhu. Multiconcept customization of text-to-image diffusion. In CVPR, 2023.</li>
</ul>
</li>
<li>line of work based on pre-training an adapter:
<ul>
<li>Guangxuan Xiao, Tianwei Yin, William T Freeman, Frédo Durand, and Song Han. Fastcomposer: Tuning-free multi-subject image generation with localized attention. IJCV, 2024.</li>
<li>Hu Ye, Jun Zhang, Sibo Liu, Xiao Han, and Wei Yang. Ip-adapter: Text compatible image prompt adapter for text-to-image diffusion models. arXiv:2308.06721, 2023.</li>
<li>Li Chen, Mengyi Zhao, Yiheng Liu, Mingxu Ding, Yangyang Song, Shizun Wang, Xu Wang, Hao Yang, Jing Liu, Kang Du, et al. Photoverse: Tuning-free image customization with text-to-image diffusion models. arXiv:2309.05793, 2023.</li>
<li>Dani Valevski, Danny Lumen, Yossi Matias, and Yaniv Leviathan. Face0: Instantaneously conditioning a text-to-image model on a face. In SIGGRAPH Asia, 2023.</li>
<li>Zhen Li, Mingdeng Cao, Xintao Wang, Zhongang Qi, Ming-Ming Cheng, and Ying Shan. Photomaker: Customizing realistic human photos via stacked id embedding. In CVPR, 2024.</li>
<li>Xiaoming Li, Xinyu Hou, and Chen Change Loy. When stylegan meets stable diffusion: a w plus adapter for personalized image generation. In CVPR, 2024.</li>
<li>Qixun Wang, Xu Bai, Haofan Wang, Zekui Qin, and Anthony Chen. Instantid: Zero-shot identity-preserving generation in seconds. arXiv:2401.07519, 2024.</li>
</ul>
</li>
</ul>

        </main>
    </div>
    <div class="lightbox-overlay" id="lightbox">
      <div class="lightbox-close" onclick="closeLightbox()">×</div>
      <div class="lightbox-content">
          <img class="lightbox-media" id="lightbox-media" src="" alt="">
      </div>
      <div class="lightbox-controls">
          <button class="lightbox-btn" onclick="zoomOut()" title="Zoom Out (-)">−</button>
          <div class="zoom-level" id="zoom-level">100%</div>
          <button class="lightbox-btn" onclick="zoomIn()" title="Zoom In (+)">+</button>
          <button class="lightbox-btn" onclick="resetZoom()" title="Reset (0)">⟲</button>
      </div>
  </div>
    <footer>
        <div class="social-links">
            <a href="https://github.com/a-r-r-o-w" target="_blank" rel="noopener noreferrer" aria-label="GitHub">
                <i class="fab fa-github"></i>
            </a>
            <a href="https://x.com/aryanvs_" target="_blank" rel="noopener noreferrer" aria-label="X (Twitter)">
                <i class="fab fa-x-twitter"></i>
            </a>
            <a href="https://linkedin.com/in/aryan-v-s" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn">
                <i class="fab fa-linkedin"></i>
            </a>
            <a href="mailto:contact.aryanvs@gmail.com" aria-label="Email">
                <i class="fas fa-envelope"></i>
            </a>
        </div>
    </footer>
    <script src="/assets/script.js"></script>
</body>
</html>
