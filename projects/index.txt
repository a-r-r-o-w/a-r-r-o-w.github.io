2:I[5314,["986","static/chunks/986-b41e40946696c600.js","895","static/chunks/app/projects/page-fc0fb44f8bc279fb.js"],""]
3:I[5613,[],""]
4:I[1778,[],""]
5:I[8632,["915","static/chunks/915-097d4a36ed8f0fca.js","185","static/chunks/app/layout-c356bb70aa365022.js"],""]
0:["K4gmFVLDlKk3DzfEMwc1U",[[["",{"children":["projects",{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],["",{"children":["projects",{"children":["__PAGE__",{},["$L1",["$","main",null,{"children":[["$","span",null,{"className":"heading","children":"personal projects"}],["$","div",null,{"className":"cards","children":[["$","$L2","0",{"url":"https://github.com/a-r-r-o-w/stablefused","name":"stablefused","description":"toy library to experiment with diffusion models","languages":["Python"],"image":null,"video":"/videos/stablefused","index":0}],["$","$L2","1",{"url":"https://github.com/a-r-r-o-w/pacman-rl","name":"pacman rl","description":"reinforcement learning environment for pacman with an api similar to openai gym","languages":["C++","Python"],"image":null,"video":"https://user-images.githubusercontent.com/72266394/274800393-591a9b7d-b287-4e28-baf8-70bae19c38c5.mp4","index":1}],["$","$L2","2",{"url":"https://github.com/a-r-r-o-w/ml/tree/master/label-classification/cpp/fashion-mnist-classifier","name":"fashion mnist classifier","description":"implmentation of a simple neural network library in c++","languages":["C++"],"image":"/images/fashion-mnist.png","video":null,"index":2}],["$","$L2","3",{"url":"https://github.com/a-r-r-o-w/ml/tree/master/label-classification/c/handwritten-digit-classifier","name":"handwritten digit classifier","description":"implmentation of a simple neural network library in c","languages":["C"],"image":"/images/handwritten-digit.png","video":null,"index":3}],["$","$L2","4",{"url":"https://github.com/a-r-r-o-w/opengl/tree/master/interactive-objects","name":"interactive objects","description":"simple game engine in opengl","languages":["C++","GLSL"],"image":"/images/interactive-objects.png","video":null,"index":4}],["$","$L2","5",{"url":"https://github.com/a-r-r-o-w/opengl","name":"opengl projects","description":"collection of simple projects made with opengl","languages":["C++","GLSL"],"image":null,"video":"/videos/convex-hull","index":5}],["$","$L2","6",{"url":"https://github.com/a-r-r-o-w/building-modelling-vr","name":"vr building modelling","description":"building modelling using blender and unity","languages":["C#","Blender","Unity"],"image":null,"video":null,"index":6}],["$","$L2","7",{"url":"https://github.com/a-r-r-o-w/competitive-programming-dbms","name":"competitive programming dbms","description":"database management system for competitive programming","languages":["Python","SQL"],"image":null,"video":null,"index":7}],["$","$L2","8",{"url":"https://github.com/a-r-r-o-w/chess","name":"chess","description":"game of chess","languages":["C","GLSL"],"image":null,"video":"/videos/chess","index":8}]]}],["$","span",null,{"className":"heading","children":"paper implementations"}],["$","div",null,{"className":"cards","children":[["$","$L2","0",{"url":"https://github.com/huggingface/diffusers/pull/7005","name":"MotionCtrl: A Unified and Flexible Motion Controller for Video Generation","description":"Implementation of the Stable Video Diffusion variant of MotionCtrl, and experiments at smaller scale with training on camera trajectory datasets.","languages":[],"image":null,"video":"/videos/motionctrl","index":0}],["$","$L2","1",{"url":"https://github.com/huggingface/diffusers/pull/6721","name":"AnimateDiff","description":"Implementation of the SDXL, ControlNet, Image-to-Video and Video-to-Video tasks. Part of official Diffusers support.","languages":[],"image":null,"video":"/videos/animatediff","index":1}],["$","$L2","2",{"url":"https://github.com/huggingface/diffusers/pull/7442","name":"Differential Diffusion: Giving Each Pixel Its Strength","description":"","languages":[],"image":"/images/differential-diffusion.png","video":null,"index":2}],["$","$L2","3",{"url":"https://github.com/huggingface/diffusers/pull/6938","name":"DragNUWA: Fine-grained Control in Video Generation by Integrating Text, Image, and Trajectory","description":"","languages":[],"image":null,"video":null,"index":3}],["$","$L2","4",{"url":"https://github.com/huggingface/diffusers/pull/7359","name":"ResAdapter: Domain Consistent Resolution Adapter for Diffusion Models","description":"Implementation of the training script.","languages":[],"image":null,"video":null,"index":4}],["$","$L2","5",{"url":"https://github.com/a-r-r-o-w/attention-is-all-you-need","name":"Attention Is All You Need","description":"Implementation of the seminal paper in PyTorch from scratch, as faithfully as possible, live-streamed on YouTube.","languages":[],"image":"/images/attention-is-all-you-need.png","video":null,"index":5}],["$","$L2","6",{"url":"https://github.com/huggingface/diffusers/pull/6315","name":"FreeInit: Bridging Initialization Gap in Video Diffusion Models","description":"Implementation generically applicable to a variety of video diffusion models. Part of official Diffusers support for AnimateDiff.","languages":[],"image":null,"video":"/videos/freeinit","index":6}],["$","$L2","7",{"url":"https://github.com/huggingface/diffusers/pull/6489","name":"Style Aligned Image Generation via Shared Attention","description":"Implementation of the attention processor to be usable in any model. Part of community Diffusers support.","languages":[],"image":"/images/style-aligned.png","video":null,"index":7}],["$","$L2","8",{"url":"https://github.com/huggingface/diffusers/pull/6490","name":"RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing with Diffusion Models","description":"","languages":[],"image":null,"video":null,"index":8}]]}]]}],null]]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","projects","children"],"loading":"$undefined","loadingStyles":"$undefined","loadingScripts":"$undefined","hasLoading":false,"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}]]},[null,["$","$L5",null,{"children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"loading":"$undefined","loadingStyles":"$undefined","loadingScripts":"$undefined","hasLoading":false,"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[],"styles":null}],"params":{}}],null]],[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/4c71f45e7ee5afc1.css","precedence":"next","crossOrigin":""}]],"$L6"]]]]
6:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","link","2",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"16x16"}],["$","meta","3",{"name":"next-size-adjust"}]]
1:null
